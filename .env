# Database Configuration
# This is your Neon connection string. Keep the single quotes!
DATABASE_URL='postgresql://neondb_owner:npg_ZgEnA2lvCBS1@ep-lucky-cloud-add2jbdu-pooler.c-2.us-east-1.aws.neon.tech/neondb?sslmode=require&channel_binding=require'

# Neo4j Configuration for Knowledge Graph
# Set up Neo4j Desktop locally. The default URI is usually correct.
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=kjkyjglc

# ----------------- LLM Provider Configuration -----------------
# We will use OpenAI defaults, but replace the API keys.
LLM_PROVIDER=ollama
LLM_BASE_URL=http://localhost:11434/v1

# *** ACTION: REPLACE THIS WITH YOUR LLM API KEY ***
LLM_API_KEY=ollama

# The LLM for the Agent's reasoning.
LLM_CHOICE=tinyllama

# Embedding Provider Configuration (used for vector creation)
EMBEDDING_PROVIDER=ollama
EMBEDDING_BASE_URL=http://localhost:11434/v1

# *** ACTION: REPLACE THIS WITH YOUR EMBEDDING API KEY ***
EMBEDDING_API_KEY=ollama

# The embedding model used for RAG. Must match the dimension below.
EMBEDDING_MODEL=all-minilm

# Ingestion-specific LLM (for entity extraction in the graph)
INGESTION_LLM_CHOICE=gpt-4.1-nano

# ----------------- Application Defaults (No need to change) -----------------
APP_ENV=development
LOG_LEVEL=INFO
APP_HOST=0.0.0.0
APP_PORT=8058

# Chunking Configuration (optimized for Graphiti token limits)
CHUNK_SIZE=800
CHUNK_OVERLAP=150
MAX_CHUNK_SIZE=1500

# Vector Search Configuration
VECTOR_DIMENSION=384   # Matches models/embedding-001 and your SQL schema
MAX_SEARCH_RESULTS=10

# Session Configuration
SESSION_TIMEOUT_MINUTES=60
MAX_MESSAGES_PER_SESSION=100

# Rate Limiting
RATE_LIMIT_REQUESTS=60
RATE_LIMIT_WINDOW_SECONDS=60

# File Processing
MAX_FILE_SIZE_MB=10
ALLOWED_FILE_EXTENSIONS=.md,.txt

# Debug Configuration
DEBUG_MODE=false
ENABLE_PROFILING=false